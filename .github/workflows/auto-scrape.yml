name: Auto-scrape Princeton Events

on:
  schedule:
    # Run every day at 6 AM UTC
    - cron: '0 6 * * *'
  workflow_dispatch: # Allow manual triggering

jobs:
  scrape-and-import:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        cd scrapers
        pip install cloudscraper beautifulsoup4 requests
        
    - name: Run scrapers
      run: |
        cd scrapers
        python combine_cloudscraper_events.py
        
    - name: Import to Cloudflare API
      run: |
        cd scrapers
        python -c "
import json
import requests

# Load the scraped events
with open('all_princeton_academic_events.json', 'r', encoding='utf-8') as f:
    data = json.load(f)

print(f'ğŸ“Š Loaded {len(data[\"events\"])} events')

# Import to Cloudflare API
api_url = 'https://princeton-academic-events.spergel-joshua.workers.dev/api/import'
headers = {'Content-Type': 'application/json'}

try:
    response = requests.post(api_url, json=data, headers=headers)
    if response.status_code == 200:
        result = response.json()
        print(f'âœ… Import successful: {result.get(\"message\")}')
        print(f'ğŸ“ˆ Events imported: {result.get(\"count\")}')
    else:
        print(f'âŒ Import failed: {response.status_code}')
        print(f'Response: {response.text}')
        exit(1)
except Exception as e:
    print(f'âŒ Error during import: {str(e)}')
    exit(1)
"
        
    - name: Verify events are loaded
      run: |
        echo "ğŸ” Verifying events are loaded..."
        
        # Check the stats endpoint
        stats=$(curl -s "https://princeton-academic-events.spergel-joshua.workers.dev/api/stats")
        echo "ğŸ“ˆ Stats: $stats"
        
        # Extract event count
        event_count=$(echo "$stats" | grep -o '"total_events":[0-9]*' | cut -d: -f2)
        
        if [ "$event_count" -gt 0 ]; then
          echo "âœ… Successfully loaded $event_count events"
        else
          echo "âŒ No events loaded"
          exit 1
        fi
        
    - name: Commit updated data
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        
        # Add the updated JSON file
        git add scrapers/all_princeton_academic_events.json
        git commit -m "Auto-update: Fresh events scraped at $(date -u +'%Y-%m-%d %H:%M UTC')" || echo "No changes to commit"
        git push || echo "No changes to push"
